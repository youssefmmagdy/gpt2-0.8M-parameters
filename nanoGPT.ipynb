{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "63a575f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "c96fdef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Shakespeare text from https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt...\n",
      "File downloaded successfully to data/shakespeare/input.txt\n",
      "File size: 1115394 characters\n",
      "Number of lines: 40000\n"
     ]
    }
   ],
   "source": [
    "# Download Shakespeare text file\n",
    "url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
    "output_path = 'data/shakespeare/input.txt'\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "print(f'Downloading Shakespeare text from {url}...')\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(response.text)\n",
    "print(f'File downloaded successfully to {output_path}')\n",
    "print(f'File size: {len(response.text)} characters')\n",
    "print(f'Number of lines: {len(response.text.splitlines())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "8b431d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "a344aa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(set(''.join(text)))\n",
    "stoi = {s:i for i, s in enumerate(chars)}\n",
    "itos = {i:s for i, s in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "914736f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(chars)\n",
    "encode = lambda s: [stoi[i] for i in s]\n",
    "decode = lambda list: ''.join(itos[i] for i in list)\n",
    "\n",
    "encoded_text = encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "0f3fabaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9 * len(encoded_text))\n",
    "train_data = encoded_text[:n]\n",
    "test_data = encoded_text[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9aca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 12\n",
    "block_size = 64\n",
    "n_embd = 128\n",
    "dropout = 0.0\n",
    "lr = 3e-4\n",
    "n_head = 4\n",
    "max_iterations = 4000\n",
    "n_layer = 4\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else test_data\n",
    "    rand = torch.randint(len(data) - block_size, (batch_size, ))\n",
    "    X = [[encoded_text[i+j] for j in range(block_size)] for i in rand]\n",
    "    Y = [[encoded_text[i+j+1] for j in range(block_size)] for i in rand]\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "0216f0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, X):\n",
    "        B, T, C = X.shape\n",
    "        k = self.key(X)\n",
    "        q = self.query(X)\n",
    "        wei = q @ k.transpose(-2, -1) * C **-0.5\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "        v = self.value(X)\n",
    "        out = wei @ v\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "c0fcb45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd) # projection layer\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "9c5ed2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedFoward(nn.Module):\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),  # projection layer\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "bb442bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head # 384 // 6 = 64 \n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "83a2e726",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        tok_emb = self.token_embedding_table(idx) # (B, T, C=32)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T))\n",
    "        x = tok_emb + pos_emb\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "        \n",
    "\n",
    "        if targets is None:\n",
    "            return logits, None\n",
    "        B, T, C = logits.shape\n",
    "        logits = logits.view(B*T, C)\n",
    "        targets = targets.view(B*T)\n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "43a3a295",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BigramModel()\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "bc4b0f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "!zv!zbezm&mtUQ&..CozIs&atgAJhNEVuJ?vbGbmEXuktvA?WaDdI&mM3K?wT-oxckmLHVDcfFiinobqASKddvfKIneHOIbCVvaC.!wn$Um ?WSITJkHvao!zAekF?TGmuDzMNiJmaEhAmW$?HNPNky?B'f EeaW3HpzJHyCFW!iLJHJcDTIx!uKtiHucM:I3RWOEIiW'NPuqT IO;vIe'\n",
      "c& ViVFXkzHIMcIXFNHxO'OI;S?'&aKtVKvYmL.vXRmbyHUhp!XV3dFIEA?BHL BfDUUMwGhFiqVSiKe?BFe$\n"
     ]
    }
   ],
   "source": [
    "print(''.join([decode(i) for i in model.generate(torch.zeros((1,1), dtype=torch.long), 300).tolist()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "038640bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8104957342147827\n"
     ]
    }
   ],
   "source": [
    "# batch_size = 32\n",
    "# block_size = 8\n",
    "for _ in range(max_iterations):\n",
    "    # forward pass\n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = model(xb, yb)\n",
    "\n",
    "    # backward pass\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    optimizer.step()\n",
    "    \n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "486ad6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Totheir that se diem.\n",
      "\n",
      "MARCIAT:\n",
      "Why have awaze and his ch, he from and,\n",
      "And chome me thy ruch to so your bold born;\n",
      "Rich eyeing livous froll'd wifef, what, word,\n",
      "Gind untrentingbmed and me mon\n",
      "Cleing with a in look my not. And your arman;\n",
      "the impatony your knove soneed, with to more course to in\n",
      "He he eath your liangoor hing appore,\n",
      "Bronge in scoularion ims, Morfort. form!\n",
      "What from made thous made and you saxted,\n",
      "I in no the a parcion to but? must fords you.\n",
      "Ah old your right, moy sorrage for a\n"
     ]
    }
   ],
   "source": [
    "print(''.join([decode(i) for i in model.generate(torch.zeros((1,1), dtype=torch.long), 500).tolist()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ee9635",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text = ''.join([decode(i) for i in model.generate(torch.zeros((1,1), dtype=torch.long), 10000).tolist()])\n",
    "with open('generated_shakespeare.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(generated_text)\n",
    "print(\"Generated text saved to generated_shakespeare.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "7385a875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816705 parameters\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in model.parameters()), 'parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feffac86",
   "metadata": {},
   "source": [
    "## Before Training (1) loss = 4.\n",
    "\n",
    "PjbrMQ\n",
    "KGNbHOXpn\n",
    "kgqcGH&v?IvLFW3tHtUKD,CTmZffJfZOgSh NWuNHQOpnNmfiW,Fn :oLcL&?hPVY-eYDjRO$?RenHlMB!gnX,ucb!dbTQ:YHxYoZFeO,VjsTd\n",
    "v'y&b\n",
    "s?cOiEOhaFHk&o.$iChEXGbM!ntE3vC?C!,'yX.SNjp:OdxUkP\n",
    "anVUhlnyphKZXsel!bvXplne$\n",
    "dFaNk?xR3ylG3DTV Sb\n",
    "?n.-Zv3,vRbz;OH;LzI:;KnBfzQi,epFfVuJI3j?jNnplp,lPcBpJn gfUvL$TlAcfA.q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd23caa",
   "metadata": {},
   "source": [
    "## After Training (2) loss = 2.5\n",
    "\n",
    "I I foleasth3:\n",
    "\n",
    "H.\n",
    "Whaswo wind a soy ran.\n",
    "F n\n",
    "Anelf avch t ta ELOS:\n",
    "INGl wea!\n",
    "D Moyemeasucend?\n",
    "-ond tal,\n",
    "Wisthoun.\n",
    "Htheld witorohemy\n",
    "And, aifean\n",
    "Ainge?T:\n",
    "E tous ierofurede my wa t Gxy thart aivut wads sorer!\n",
    "\n",
    "Ssouresll?\n",
    "Ses tonk:\n",
    "Pr g\n",
    "Firyemire\n",
    "Yiserore kitl and towo t chathy'd inee Hemod the ha ser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cec6fa6",
   "metadata": {},
   "source": [
    "## After Training with Head-Attention (3) loss = 2.4\n",
    "Tallo korlend hin liloray ds om thrennm whe. ''ptor; kein here heak\n",
    "Whofo man alr:\n",
    "QIat: htile st bry ss!\n",
    "\n",
    "D:\n",
    "ARNGNAASow he's ind ave-for,\n",
    "Anaw, mave thy,\n",
    "Lon fe.\n",
    "\n",
    "Hathule, ared ad bunt out a brinol, miteree per weyol wourglandour.\n",
    "\n",
    "Tha wh oghou ongs forgeis, 'ble ce kigrtorung fe: nd.\n",
    "\n",
    "Lth se toeal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e42d03",
   "metadata": {},
   "source": [
    "## After Training with Multi-Head-Attention & FFN (4) loss = 2.2\n",
    "\n",
    "CHINI weathctiong\n",
    "Fony,! nont by fuen theace:\n",
    "reagcent, I'KSirn ond K:\n",
    "Bownce;\n",
    "And hawaws:\n",
    "Ath rof end nincke filt ist I a be.\n",
    "\n",
    "AKENE:\n",
    "Omy, ustiin otul'd amy fromse my to gind gon and\n",
    "Hameands.\n",
    "\n",
    "FRAO IULE: and may me:\n",
    "ntilde hus, wicr Chape ined, wuring:\n",
    "Atwh me;\n",
    "Teat I loots ay.\n",
    "Ad. not :\n",
    "Piot nowo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c230ad",
   "metadata": {},
   "source": [
    "## After Training with Blocking (5) loss = 1.9\n",
    "\n",
    "Shy-now I kencroural, am thee cess\n",
    "Mecce,\n",
    "On that deave beacity have, the chat Casssurs,\n",
    "It and jeepould play.\n",
    "So this a intul corte Etil neise wile.\n",
    "Herviey if parth I sir fram this save and sple, Haw share is upirsit, doth that thall\n",
    "Of upoy.\n",
    "Bea.\n",
    "\n",
    "LARY:\n",
    "Nare counter; make he bake a pleanter, and "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47271fe",
   "metadata": {},
   "source": [
    "## Final Trainings (6) loss = 1.8\n",
    "\n",
    "Totheir that se diem.\n",
    "\n",
    "MARCIAT:\n",
    "Why have awaze and his ch, he from and,\n",
    "And chome me thy ruch to so your bold born;\n",
    "Rich eyeing livous froll'd wifef, what, word,\n",
    "Gind untrentingbmed and me mon\n",
    "Cleing with a in look my not. And your arman;\n",
    "the impatony your knove soneed, with to more course to in\n",
    "He he eath your liangoor hing appore,\n",
    "Bronge in scoularion ims, Morfort. form!\n",
    "What from made thous made and you saxted,\n",
    "I in no the a parcion to but? must fords you.\n",
    "Ah old your right, moy sorrage for a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
